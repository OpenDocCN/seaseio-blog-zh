# 每日歌曲排序问题的学习排序项目-第 3 部分

> 原文：<https://web.archive.org/web/sease.io/2021/03/a-learning-to-rank-project-on-a-daily-song-ranking-problem-part-3.html>

我们又来了，用新的知识来排列实现。

如果你正在阅读这篇博文，你可能已经熟悉我们关于每日歌曲排名问题的内部项目，在我们以前的博客([第一部分](https://web.archive.org/web/20221130071151/https://sease.io/2020/12/a-learning-to-rank-project-on-a-daily-song-ranking-problem.html)和[第二部分](https://web.archive.org/web/20221130071151/https://sease.io/2021/02/a-learning-to-rank-project-on-a-daily-song-ranking-problem-part-2.html))中有所描述。如果没有，我建议你先读一读，以便更好地理解我在这里要阐述的内容。

在深入研究这种新方法的细节之前，让我们先对我们的项目做一个简短的总结:

在第一篇博文中，我们展示了建立学习排名(LTR)系统的流程:我们从可用的数据开始，一个 Kaggle 数据集[【1】](https://web.archive.org/web/20221130071151/https://www.kaggle.com/edumucelli/spotifys-worldwide-daily-song-ranking)；我们通过几个数据清理和特征工程技术操纵它；我们创建了训练集和测试集，最后，我们使用 XGBoost 训练了一个排名模型。

在第二篇博文中，我们使用子集而不是完整的数据集进行了进一步的分析，以检查模型性能方面的差异。我们还通过使用名为 SHAP 的强大库来解释模型的行为。

在这篇博文中，**我们将创建一个新的查询 Id，并检查在构建训练集时发生了什么。**

在前面的实验中，我们从单个特征(“Region”列)生成了“query_ID ”,而没有考虑歌曲排行榜的日期。在博客文章[第二部分](https://web.archive.org/web/20221130071151/https://sease.io/2021/02/a-learning-to-rank-project-on-a-daily-song-ranking-problem-part-2.html)的第二节中描述的分析过程中，我们意识到我们可以将查询视为多个查询级别特征的散列，以避免每个查询的歌曲“重复”:在特定地区的歌曲排行榜中，一首歌曲可以在排行榜上的同一位置停留几天，甚至几周。

此外，如果我们还考虑歌曲图表的日期(日、月和工作日)，我们将获得更具体的查询，从而获得更准确的搜索结果，以便我们可以更好地代表用户的意图和他的需求。

## 查询 Id 生成

您应该仔细设计如何计算查询 Id。

**查询 Id 表示每个查询文档样本中< Q，D >的 Q，并且您的数据集中的相同查询必须具有相同的 Id。**

最简单的方法是当您的查询只是一系列自由文本术语时；因此，您必须将相同的术语序列与相同的查询 Id 相关联。仅此而已。

有时，您可能有一个由用户在搜索过程中选择的一系列过滤查询表示的查询。如果是这样，您可能希望将查询 Id 作为这些过滤器的组合来计算。查询越准确，搜索结果就越好。
事实上，生成查询 Id 的另一个好方法是将所有查询级别的特性串联起来(**简单散列，聚类**)。

*查询级(或查询相关)特征描述了查询的属性，它们的值仅取决于查询实例。*
在我们的例子中，它们是地区、日、月和工作日。

所以我们决定修改我们的管道，创建一个不同的查询 Id。
让我们回到预处理部分，通过使用一种新方法来生成它:

```
def **generate_id_from_columns**(input_data_frame, query_features, id_column):
    str_id = input_data_frame[query_features[0]].astype(str)
    for feature in query_features[1:]:
        str_id = str_id + '_' + input_data_frame[feature].astype(str)
    input_data_frame[id_column] = pd.factorize(str_id)[0]
```

在我们的例子中，参数是:

*   *   **input_data_frame** 是 Spotify 数据集(CSV 文件)
    *   **query_features** 由以下查询级特性的集合表示:区域、日、月和工作日。
    *   **id_column** 是我们想要创建的特征(我们称之为' ***query_ID'*** )

一旦创建了“ **str_id** ”作为多个特性的散列，我们就用 Pandas factorize()函数对其进行操作，该函数将每个字符串与一个整数唯一地链接起来。

在这里，您可以找到一个示例来理解查询 Id 创建中的差异:

![](img/db3e084e642aff3ff09c9c1dbc52fc91.png)

(请注意:为了稍后与“旧”模型进行比较，我们没有删除用于构建查询的日、月和工作日功能。)



我们还做了一些统计分析来比较新旧查询 Id。在下表中，您可以看到在新的实现中，我们有了更多的查询(从 54 个到 19675 个),并且每个查询的观察值更少。基本上，虽然我们以前每个查询有大约 400 个歌曲排行榜，但现在我们只有一个，包含多达 200 首歌曲(在某些情况下，我们没有完整的排行榜)。标准差告诉我们每个查询 Id 的行数是否均匀分布。由于这是两个完全不同的实现，所以不容易做直接的比较；然而，我们可以说，在这两种情况下，超过 80%的查询 id 包含超过设定阈值的足够数量的样本，这可能是好的。

![](img/3b9a1ef36fbeb46aaa53d9ac6acb1cb9.png)

## 训练集和测试集分离

一旦我们获得了具有新查询 Id 的数据帧，我们就按照以前的博客文章中采用的相同实现将其分为训练集和测试集，我将在这里更具体地描述:

1.  1.  如果我们的查询 id 有一些低于某个阈值的观察值，我们将这些观察值保存在一个名为 **under_sampled_only_train** 的新数据帧中，因为我们只希望它们出现在训练集中。只有当测试集出现的次数少于整个数据集的 20%时，我们才把它们中的一些移到测试集(具有最高观察次数的查询 id)。
    2.  所有的相关性标签必须平均分布。事实上，我们为每个相关性标签手动选择所有观察值的 20%,并将它们移动到测试集。这样做，我们确保所有的相关性标签，从 0 到 20，都在两个集合中。

有了新的查询 Id，我们意识到这个实现不能被应用。在这种情况下，对于每个查询，我们只有一个歌曲图表，因此假设只有一首歌曲具有最高的相关性(在图表的第一个位置):由此得出结论，我们只有一个相关性标签为 20 的观察结果，并且它永远不会出现在测试集中。

为简单起见，我们以 query_ID = 0 为例。在下表中，您可以更好地理解到目前为止所解释的内容。
查询 0 有 200 个观测值(一张宋图)；我们只有很少的相关性标签从 10 到 20 的观察结果(正如在[第 1 部分——相关性评级](https://web.archive.org/web/20221130071151/https://sease.io/2020/12/a-learning-to-rank-project-on-a-daily-song-ranking-problem.html)中应用的映射所预期的那样),它们永远不会被移动到测试集中。为什么？

*   *   对于**相关性标签= 0** ,我们总共有 50 个观察值，我们取这些观察值的 20%,因此 10 行将被移动到测试集。
    *   对于 **Relevance Label = 7** 我们总共有 10 个观察值，我们取这些观察值的 20%,因此将有 2 行被移动到测试集。
    *   对于 **Relevance Label = 10** ，我们总共有 3 个观察值，3 的 20%是 0.6，因此没有行将被移动到测试集(对于剩余的行也是如此)。

因此，不可能在两个集合中都有所有的相关性标签。

![](img/0d4bbac85d90a92aa37d9a459cb73586.png)

我们决定实现一种不同的方法:我们随机打乱数据帧，然后将其分成训练集和测试集，确保每个查询 Id 的 20%的观察结果移动到测试集，而与相关性标签无关。当然，最好在两个集合中都有相关性标签，但这样一来，它们的分布至少变得更加公平。

![](img/43bfb30dd7e39faa2c01f6f67e0d29f9.png)

最后，我们使用 LambdaMART 训练了一个学习排序模型。使用旧的分割，我们将在具有所有相关性标签的样本上训练模型，但是它们中的大多数(从 10 到 20)将不会被测试，因为它们不存在于测试集中。如果没有对一部分重要数据进行测试，我们如何判断模型是否表现良好？！

## 结果

在这个新的实施中，我们采取了不同的方法，将管道分为两个部分:

1.  1.  当生成查询 Id 时
    2.  在我们分割数据集的阶段

让我们检查获得的结果:

![](img/fa3f465eef8b1b9459b5a196d9a24d67.png)

您可以看到，我们使用哈希编码的变体(对于‘Title’特性)比另一个变体(Doc2Vec 编码)具有更好的模型性能。

使用哈希编码，我们检查了使用新旧查询 Id 训练模型之间的差异，然后我们在相同的测试集上测试了这些模型。两个型号的特征相同，因此可以进行比较；唯一改变的是查询 Id。在第一个实现(OldQueryId 模型)中，我们的目标是获得基于地区的最佳排序，而现在我们的目标是获得基于地区、日、月和工作日的最佳排序。

当我们使用两个不同模型的训练集和测试集时，我们必须确保它们之间没有交集:这意味着测试集的观察值在训练时必须是未知的。



例如，我们以“OldQueryId 模型”的训练集和“NewQueryId 模型”的测试集为例。我们必须检查它们是否有共同的观察值，这意味着如果两行对于除查询 Id 之外的所有特性都有相同的值，我们就认为这两行是相同的。我们在 Pandas[【2】](https://web.archive.org/web/20221130071151/https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html)中使用了合并功能:

```
intersections = training_set.merge(test_set, how='inner', on='cols')
```

其中:

*   *   **交集** =将包含训练集和测试集之间共有的所有行
    *   **training_set** :数据帧=旧查询 Id 的训练集
    *   **test_set** :要合并的对象=具有新查询 Id 的测试集(哈希)
    *   **如何**:要执行的合并类型= *'内部*'连接以获取交集
    *   **on**:column to join on = '*cols*'(除查询 Id 外的所有特性)



查询 Id 被排除在外，因为它是在这两个实现过程中唯一被不同操作的特性。在匹配的情况下，我们从训练集中删除公共行，并将它们留在测试集中。

![](img/747e97806b11997dfa44e4fce06609c8.png)

总的来说，我们可以看到使用新查询 ID 的模型性能更好。作为多个查询级别特征的散列的查询 Id 能够返回更好的搜索结果排序。当我们使用新 query_ID 的训练集和旧 query_ID 的测试集(反之亦然)时， *train-ndcg@10* 下降了一点点。这可能是因为从定型集中删除了公共行，因此模型需要学习的输入数据较少。

###### 最终考虑

**如果可能，查询 Id 应包含所有查询级别的特征**。

**目标是达到每个查询 Id 样本的均匀分布。**事实上，您需要小心计算查询 id 的方式:如果粒度太细，您可能会得到很多样本很少的查询 id；另一方面，如果你放松你的粒度，你可能最终会得到一个庞大的排名列表，但却不那么精确，因为它们代表了更广泛的概念。你应该试着平衡一下。

**如果查询 id 欠采样，则丢弃训练样本**。也许还应该说，这必须语境化。如果我们有可靠的数据，并且确信我们已经适当地管理了可能导致 NDCG 暴涨的条件，我们可以尝试将这些观察值保留在训练集中，或者为所有这些观察值分配一个新的查询 Id。

如果您清理数据集，然后分割它，您必须小心，因为您可能会得到一个不公平的测试集:

*   *   测试集不能有欠采样的查询 id
    *   测试集不能有带有单个相关性标签的查询 id
    *   测试集必须具有代表性，并且具有可接受的大小(根据每个查询的观察值)
    *   可能地，所有相关性标签都应该在两个集合中

// our service

## 不要脸的塞给我们培训和服务！

我提到过我们做[学习排名](https://web.archive.org/web/20221130071151/https://sease.io/learning-to-rank-training)和[搜索相关性](https://web.archive.org/web/20221130071151/https://sease.io/training/search-relevance-training/search-relevance-training-solr)培训吗？
我们还提供关于这些主题的咨询，[如果您想让您的搜索引擎更上一层楼，请联系](https://web.archive.org/web/20221130071151/https://sease.io/contacts)！

// STAY ALWAYS UP TO DATE

## 订阅我们的时事通讯

你喜欢这篇关于 Drop constant features:一个现实世界的学习排名场景的帖子吗？不要忘记订阅我们的时事通讯，以便随时了解信息检索世界的最新动态！