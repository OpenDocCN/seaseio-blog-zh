# 每日歌曲排序问题的学习排序项目-第 2 部分

> 原文：<https://web.archive.org/web/sease.io/2021/02/a-learning-to-rank-project-on-a-daily-song-ranking-problem-part-2.html>

如果你已经阅读了这篇博文的第 1 部分，你应该已经知道如何从可用的数据开始，使用开源库来建立一个学习排名(LTR)系统。

我们以未来工作的部分结束了这篇文章，其中我们提到了我们想要解决的三个方面。所以这篇博文分为三个主要部分:

*   *   在**的第一部分**中，我们对数据集进行采样，因为我们有兴趣发现，在拥有更少数据的情况下，我们是否仍然可以获得一个好的模型，从而获得与使用完整数据集进行训练类似(或更好)的结果。
    *   在**的第二部分**，我们希望了解如果我们通过直接排序特定特征的值(在我们的例子中是降序)而不训练任何模型来对结果进行排序，会发生什么。
    *   第三部分涉及通过使用库 SHAP 来解释模型的行为；特别是，我们将看到每个特性如何影响模型的输出。

【T8

让我们一起，一个接一个地，来看看为解决上述问题而执行的 3 个不同实现所获得的结果。

## 1)如果在对我们的数据集进行采样之后，我们根据歌曲位置值来估计相关性标签，会发生什么？

我们通过使用一个只从数据帧中过滤特定行的 [Pandas](https://web.archive.org/web/20221202222543/https://pandas.pydata.org/pandas-docs/stable/getting_started/intro_tutorials/03_subset_data.html) 函数，对我们的**完整数据集**进行了采样；特别是，我们感兴趣的是获得仅包含从位置 1 到 21 的每日歌曲图表的子集:

```
subset = data_frame[data_frame["Position"] <= 21]
```

我们得到了一个由 412.385 个观察值组成的**子集**，约占整个数据集的 12%，它包含完全相同的数据结构(参见之前博客文章中解释的数据预处理和特征工程部分)。

我们已经直接从完整数据集的训练集和测试集中提取了训练集和测试集(80:20)(这是出于一般考虑中的第二个原因)。特征‘位置’(从 1 到 21)用于估计相关性等级，我们的目标变量；因此，从 0 到 20 的相关性标签是通过以降序颠倒位置值来获得的。这样做是为了使图表上第一个位置(位置 1)的歌曲具有最高的相关性标签(20)，而图表上最后一个位置(位置 21)的歌曲具有最低的相关性标签(0)。

然后，我们使用为主要项目选择的相同算法和相关参数(在[第 1 部分](https://web.archive.org/web/20221202222543/https://sease.io/2020/12/a-learning-to-rank-project-on-a-daily-song-ranking-problem.html)中描述)训练模型，并且我们使用相同的测试集评估模型的性能，以便在相同的“操场”上比较它们；获得的结果如下表所示:

![](img/46d9645a7c876e630e9b14f669608fab.png)

###### 一般注意事项:

1.  1.  使用子集的模型训练明显更快
    2.  我们必须确保训练集和测试集之间没有交集；这意味着测试集的观测值在训练时必须是未知的
    3.  尽管数据较少，但使用子集构建的模型具有最佳性能；一个原因可能是整个数据集比子集具有更大的可变性
    4.  将 Doc2Vec 编码应用于音轨名称变量在整个数据集中似乎比在子集中更好
    5.  当我们使用较小的测试集时，我们得到了更好的结果，尽管没有实质性的差异。在这个领域中，子集的测试集的维度(大约 84.000 个观察值)已经给了我们足够的信息。通常，我们会想象测试集越大越好；实际上，存在一个阈值，超过这个阈值，增加测试集的维数不会带来任何好处。

我们还研究了为什么在使用 Doc2Vec 编码时，eval ndcg@10 的值大于 train ndcg@10(一般情况下应该相反)。这是一种罕见的现象，但它可能发生在任何 ML 模型上；有几个原因:

*   *   测试集大小可能太小
    *   测试集由比训练集“更容易”的例子组成
    *   在我们的数据集中没有太多的差异
    *   我们的训练/测试分割适用于这种偶然行为

无论如何，在这种情况下，差异是无关紧要的，但如果这是一个非常大的差异，我们需要进一步调查。一个建议是尝试使用 k-fold 交叉验证，或者如果模型需要太多时间来训练，就在不同的混合训练/测试集上重新训练，以查看趋势是否持续。

## 2)此外，如果我们直接使用流计数(降序)对结果进行排序，会有什么变化？我们会在搜索结果列表中得到相同的顺序吗(因此最大 NDCG)？！

为了找到这个问题的答案，我们使用了在数据预处理部分之后获得的完整数据集(具有从 0 到 20 的相关性标签)。

**请注意**:在下面的所有图像中，相关性标签由排名栏表示

T13T15

由于我们的目标是通过“流”计数对歌曲进行排序，因此查看一下**相关矩阵**是非常有用和有趣的，该表显示了变量之间的相关系数:

![](img/3b31a2584a6464dec6370ae69a18aa84.png)

我们可以看到，流与位置(-0.1339)、流与排名(0.1697)之间的相关性很低，而位置与艺人之间的相关性最高(0.4665)。



我们根据'**流**'特性对整个数据集进行降序排序，通过下面的代码行按 **query_ID** 分组:

```
data_frame_sorted = data_frame.groupby(["query_ID"]).apply(lambda x: x.sort_values(["Streams"], ascending=False)).reset_index(drop=True)
```

一旦我们获得了有序数据集，我们就通过一部分代码手动计算 NDCG@10，其中我们只对每个查询的搜索结果列表的前 10 首歌曲直接应用 DCG 公式及其归一化变体。在下面的示例中，您可以看到分别针对 query_ID = 0 和 query_ID = 1 返回的前 10 个结果。

![](img/a6b87a4e64c49c4886a2d29c01535275.png)

在排序后的数据集上，我们对“排名”列应用了以下步骤(针对每个查询):

*   *   算一下**DCG @ 10**[【1】](https://web.archive.org/web/20221202222543/https://machinelearningmedium.com/2017/07/24/discounted-cumulative-gain/)

*   *   计算出**理想的 DCG@10**

*   *   算算 **NDCG@10** *= DCG@10/理想的 DCG@10*

*   *   **对所有查询的 NDCG@10 值进行平均**

最终结果是 **NDCG@10 = 0.9347**

在没有训练任何模型的情况下，我们通过直接使用流计数以降序对歌曲进行排序，获得了良好(以及更好)的 NDCG。从上图可以看出，对于查询 0，最大数据流都与图表顶部位置(排名 20)的歌曲相关，而对于查询 1，最大数据流与图表上的较高位置相关，但结果是分散的。

此外，我们还注意到，对于一些查询(如查询 0)，排序列表的第一个结果总是由不同日期的同一首歌曲(相同的 **ID** 表示。假设一个搜索引擎返回一系列相同的项目(相同的歌曲)是没有意义的。我们决定只保留每首歌曲和每个查询的最大数据流数量的观察值:

![](img/5a935fabf35c55bb244d6f27bd9a37d9.png)

再次按降序排序后(从上面关于查询 0 的图片中可以看到)，最终结果(所有查询的平均值)是 **NDCG@10 = 0.8212** 。在这种情况下，删除一些观察值会使性能变差。

###### 子集

我们使用子集而不是完整数据集重复了相同的实验，这些是观察到的结果:

1.  1.  变量之间的相关性较小:
        *   位置和流之间的相关性为: **-0.0810**
        *   排名和流之间的相关性是: **0.0810**
        *   位置与艺术家的相关性为: **0.1563**
    2.  相同的 NDCG@10 ( **0.9347** )
    3.  NDCG@10 略低( **0.8176** 而不是 **0.8212** )，此时我们只保留了每首歌曲的最大流的观察值。

## 3)通过使用库 SHAP 给出模型行为的解释，特别是每个特征如何影响模型的输出

如果你错过了我们之前关于 [SHAP](https://web.archive.org/web/20221202222543/https://sease.io/2020/07/explaining-learning-to-rank-models-with-tree-shap.html) 的博文，请先阅读它，了解这个库的惊人工具，以及如何解释学习使用 TreeSHAP 算法对模型进行排序。

到目前为止，我们已经创建了一个数据集(完整)和一个子集，我们已经使用不同的数据预处理技术训练了几种类型的模型，现在我们想了解这些模型是如何实现这些结果的。

我们对 4 种不同的模型进行了比较:

![](img/04da68d714931f190b4c96504d537811.png)

SHAP 库[【2】](https://web.archive.org/web/20221202222543/https://github.com/slundberg/shap)为每个预测创建模型解释，并描述如果从模型中移除特征 *y* 预测 *x* 如何变化。所谓的 **SHAP 价值观**就是答案。

由于我们使用 LambdaMART(多重加性回归树)构建 LTR 模型，因此我们使用了**tree explainer**[【3】](https://web.archive.org/web/20221202222543/https://shap.readthedocs.io/en/latest/examples.html#tree-explainer)，这是一种在多项式时间内计算树和树集合的 SHAP 值的算法。

TreeSHAP 为我们提供了几种不同类型的绘图，每一种都突出了模型的一个特定方面。Matplotlib ，一个非常有用的可视化库，用于 Python 中图形的渲染。

###### 汇总图



概要图给了我们**全局可解释性**。使用带有 plot_type = " **bar** 的 **shap.summary_plot** 函数，您可以用 x 轴上的平均值(|SHAP 值|)生成特征重要性图(按降序排列的变量)。

![](img/b35802dc16442506746c4cb0a596b95f.png)

我们可以看到，*流*功能实际上是最重要的，其次是*艺术家*功能。



如果您想要显示预测值与目标变量的正负关系，您必须生成另一种类型的汇总图:

![](img/e601091d19f00fefe3549c11060dfb76.png)

这些图不仅显示了可变的重要性(从上到下)，还显示了特征值(使用从蓝色到红色的色谱)如何影响标签预测；每个观察(歌曲)，每行都有一个点。

这里，流的数量越多，对相关性的正面影响就越高(SHAP 值大于零)；而‘艺术家’特征与目标变量负相关。如果您还记得，Artists 列是使用留一技术编码的，该技术用与该级别相关的目标变量值的平均值替换分类值，但在计算平均值时排除当前行的目标值；因此，这个数值本身并不重要，但是更有趣的是知道哪个艺术家对应于那个值，以了解谁是最受欢迎的。

其他特征的排序看起来有点不同，但是总体上我们可以说该子集足以代表整个数据集。

###### 决策图

决策图[【4】](https://web.archive.org/web/20221202222543/https://slundberg.github.io/shap/notebooks/plots/decision_plot.html)展示了模型如何做出决策，显示了每个特征的累积效应。每条垂直线代表一个预测:

![](img/3aa7c2e006a3dafec5f726b7ded853a6.png)

该系统无法获得完整数据集的图表，因此我们只能获得 500.000 个观察值的图表。有趣的方面是，在 M1 和 M2 中，已经编码的特征(col_0 到 col_7)干涉轻微，线条几乎是直的(可能因为是二元变量)；另一方面，在 M3 和 M4 有更多的可变性，但是编码特征(0 到 99)太多了，很难分辨哪个音轨名称最有影响。



为了更好地理解决策图，让我们只考虑一个观察。下图显示了不同要素值对单个选定预测的影响，以及它们对模型的正面或负面影响。在我们的案例中，我们总是在不同的模型中绘制相同的观察结果(宋):

![](img/1881f6f630cbca38939750c2ca642ce2.png)

例如，在第一个图表中，我们可以看到第 3 个月、第 3 个工作日、第 16 天、col_3 True、Artists 45.981 对模型有正面影响，而其他功能有负面影响。

有趣的是，同一个特征值对最终模型输出的影响不同；此外，使用完整数据集，我们获得的模型输出值大于使用子集时的值(M2 为 4.79，M1 为 0.19，M4 为 3.52，M3 为 0.09)。区别是实质性的:原因可能是删除一些观察值会降低相同观察值的重要性。

###### 力图

这个图给了我们一个**局部可解释性**，显示了单次观察的 SHAP 值。为了简单起见，让我们采用与上面相同的观察结果，并且只显示一个代表 M1 的力图:

![](img/592725cf292ce4f9ff69857aa0470fad.png)

从这个图中，你可以看到:

*   *   **f(x)** 是模型预测值(0.19)
    *   **基值**，即如果我们不知道当前输出的任何特性时预测的值
    *   每个要素对输出的影响方式和程度:将预测值推高的要素显示为红色，将预测值推低的要素显示为蓝色。“艺术家”是 45.9809(即 Luis Fonsi)的事实产生了积极影响，而“流”是 27748 的事实产生了消极影响。

现在应该考虑 4 个不同的观察值，并检查其模型的输出值。回答特定查询(例如 **query_ID = 0** 对应于 **Ecuador** 地区)的这些歌曲的 SHAP 得分在下表中被报告和排序:

![](img/48255fe6d9247a6fc20fcd4daa7c1785.png)

该模型的输出不是相关性标签，但是如果我们观察歌曲之间的 SHAP 分数的相对相关性，它代表相同的概念。由于 0.19 > -4.42 > -4.96 > -9.02，使用 SHAP 分数或相关性标签，结果的排序将是等同的。

###### 依赖图

###### T2T4

依赖图[【5】](https://web.archive.org/web/20221202222543/https://slundberg.github.io/shap/notebooks/plots/dependence_plot.html)显示了两个特征对模型预测结果的边际影响。作为第一个例子，我报告了流和艺术家之间的依赖图:

![](img/394afc16737862036b97126e80612418.png)

这里每个点对应一个预测；在 x 轴上，我们有流值，在 y 轴上，我们有预测的 SHAP 值，颜色代表艺术家。我们可以看到一个很奇怪的情况:在流数很低的情况下，每个艺人真的会有所作为；反之亦然，在某个阈值之后，每个艺术家以相同的方式影响，并且 SHAP 值是高的和恒定的。



作为第二个例子，我使用相同的特征报告了依赖图，但是在轴上颠倒了它们:

![](img/84a42233e19ef6b5e74fae532ea7c39b.png)

即使在这种情况下，我们也能注意到“艺术家”造成了差异:艺术家的价值观< 50 (plus or minus) produce higher SHAP values than the others. As mentioned above, the ‘Artists’ feature has been encoded with a technique based on the mean of the target variable values (Position on chart) so the Artists who are known to always be in the highest positions are also those who have the lowest encoding values (so the average of the Position values < 50). This result suggests that Artists who have the same relevance, also have the same impact on the model; therefore the most popular Artists positively affect the model’s output.

T3

我们还可以为图表的日期创建这种绘图，也就是说，分别为日、月和工作日功能创建这种绘图，并根据流的数量给点着色:

![](img/14738109baca862ba13563cbbb081841.png)

在这种情况下，我们可以立即看到，日和工作日对完整数据集中的模型输出没有影响(这反映了汇总图的结果)。只有某些日子的流量比其他日子多(例如星期天)。

在子集中，不考虑流，我们可以注意到前半个月、前半年和前半周比后半周产生更大的 SHAP 值，这意味着对输出的积极影响。无论如何，没有额外的信息，很难解释这种类型的行为。

###### 摘要

让我们在一个每日歌曲排名问题上回顾一下学习排名项目的要点。



在第一篇博文中，我们展示了从可用数据开始，创建和操作训练集和测试集，然后使用开源库训练排名模型，建立和构建学习排名(LTR)系统的管道。在第二篇博文中，我们通过处理数据进行了进一步的分析，以寻找见解，并通过使用 SHAP 图书馆对模型的行为进行了解释。所有获得的结果都是在 Kaggle[【6】](https://web.archive.org/web/20221202222543/https://www.kaggle.com/edumucelli/spotifys-worldwide-daily-song-ranking/home)上关于全球每日歌曲排名的 Spotify 数据集上计算的。

###### 外卖食品

*   *   数据预处理和特征工程是至关重要的，也是我们应该更加重视的部分
    *   当我们有一个更大的数据集时，Doc2vec 编码技术在模型性能上似乎比哈希编码更好
    *   较小的数据集可变性较小，可能更容易理解，但代表性较差
    *   评估 ndcg@10 值可能大于训练 ndcg@10 值
    *   特别是在某些领域，存在一个阈值，超过这个阈值，增加测试集的大小不会带来任何改进
    *   在不训练任何模型的情况下，我们可以通过直接排序(降序或升序)特定特征的值来获得结果的良好排序
    *   SHAP 图书馆是解释这一特性重要性的有力工具。一些图表向我们展示了许多见解，有助于理解每个变量如何影响模型的输出；然而，如果不了解我们工作的背景，就不容易给出详尽的解释。

###### 未来作品

到目前为止，我们只从 Region 列生成了“query_ID ”,而没有考虑歌曲排行榜的日期。在这篇博文第二部分描述的分析过程中，我们意识到我们可以把它看作是多个查询级别特性的散列，以避免每个查询的歌曲“重复”。在下一篇博文中，我们将创建 query_ID 作为多个变量(地区、日期、月份和工作日)的散列，我们将再次对获得的模型进行比较。

我希望这两篇博客文章很有趣，并且你已经学会了处理 LTR 任务和进行相关调查所需的工具。

// our service

## 不要脸的塞给我们培训和服务！

我提到过我们做[学习排名](https://web.archive.org/web/20221202222543/https://sease.io/learning-to-rank-training)和[搜索相关性](https://web.archive.org/web/20221202222543/https://sease.io/training/search-relevance-training/search-relevance-training-solr)培训吗？
我们也提供这些主题的咨询，[如果你想让你的搜索引擎更上一层楼，请联系](https://web.archive.org/web/20221202222543/https://sease.io/contacts)！

// STAY ALWAYS UP TO DATE

## 订阅我们的时事通讯

你喜欢这个帖子吗？这个帖子是关于一个关于每日歌曲排名问题的学习排名项目。不要忘记订阅我们的时事通讯，以便随时了解信息检索世界的最新动态！